# -*- coding: utf-8 -*-
"""Copy of Car or Truck_AML_Project2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mN2Y7gfepbH3brj4S9uAKkI_xXYP13Dv
"""

from google.colab import drive
drive.mount('/content/gdrive')

! ls -s /content/gdrive/MyDrive/carVtruck.zip

!unzip "/content/gdrive/MyDrive/carVtruck.zip" -d "/content/gdrive/MyDrive/PML"

! ls

import os
import numpy as np
import pandas as pd
import torch
import matplotlib as plt
from PIL import Image
import matplotlib.pyplot as plt
from sklearn.cluster import AgglomerativeClustering
from sklearn.metrics import pairwise_distances
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.applications.resnet50 import preprocess_input

# Define paths
train_car_path = "/content/gdrive/MyDrive/PML/train/Car"
train_truck_path = "/content/gdrive/MyDrive/PML/train/Truck"

# Define Df for trucks and cars

truck_df = pd.DataFrame(columns=['Image', 'Path'])
car_df = pd.DataFrame(columns=['Image', 'Path'])

def load_and_preprocess_image(image_path):
    img = load_img(image_path, target_size=(224, 224))
    img = img_to_array(img)
    img = preprocess_input(img)
    return img

def load_and_preprocess_image(image_path):
    img = load_img(image_path, target_size=(120, 120))
    img = img_to_array(img)
    img = preprocess_input(img)
    return img

truck_images_folder = "/content/gdrive/MyDrive/PML/train/Truck"
for image_file in os.listdir(truck_images_folder):
    image_path = os.path.join(truck_images_folder, image_file)
    img_data = load_and_preprocess_image(image_path)
    truck_df = truck_df.append({'Image': img_data, 'Path': image_path}, ignore_index=True)

car_images_folder = "/content/gdrive/MyDrive/PML/train/Car"
for image_file in os.listdir(car_images_folder):
    image_path = os.path.join(car_images_folder, image_file)
    img_data = load_and_preprocess_image(image_path)
    car_df = truck_df.append({'Image': img_data, 'Path': image_path}, ignore_index=True)

truck_df

chosen_image_index = 1
chosen_image = truck_df.loc[chosen_image_index, 'Image']
chosen_image_path = truck_df.loc[chosen_image_index, 'Path']

plt.imshow(chosen_image)
plt.title(f"Truck Image: {chosen_image_path}")
plt.axis('off')  # Turn off axes
plt.show()

image = Image.open("/content/gdrive/MyDrive/PML/train/Truck/00001.jpeg")
plt.imshow(image)

"""new"""

def load_and_preprocess_images(image_folder):
    images = []
    for image_file in os.listdir(image_folder):
        img = load_img(os.path.join(image_folder, image_file), target_size=(224, 224))
        img = img_to_array(img)
        img = preprocess_input(img)
        images.append(img)
    return images

train_car_images = load_and_preprocess_images(train_car_path)
train_truck_images = load_and_preprocess_images(train_truck_path)

train_car_images

# Combine images and calculate features
all_images = np.vstack((train_car_images, train_truck_images))

# Calculate pairwise distances
distances = pairwise_distances(all_images.reshape(len(all_images), -1), metric="euclidean")

# Agglomerative Clustering
num_clusters = 2  # Number of clusters (cars and trucks)
agg_clustering = AgglomerativeClustering(n_clusters=num_clusters, affinity='precomputed', linkage='average')
cluster_labels = agg_clustering.fit_predict(distances)

# Print cluster labels
print("Cluster labels:", cluster_labels)

from sklearn.cluster import AgglomerativeClustering
from sklearn.metrics import pairwise_distances
from scipy.cluster.hierarchy import dendrogram, linkage


linkage_matrix = linkage(distances, method='average')
plt.figure(figsize=(10, 5))
dendrogram(linkage_matrix, labels=cluster_labels, leaf_rotation=0, leaf_font_size=12)
plt.xlabel('Image Index')
plt.ylabel('Distance')
plt.title('Agglomerative Clustering Dendrogram')
plt.show()

"""Changed the metrics"""

# Combine images and calculate features
all_images = np.vstack((train_car_images, train_truck_images))

# Calculate pairwise distances
distances = pairwise_distances(all_images.reshape(len(all_images), -1), metric="manhattan")

# Agglomerative Clustering
num_clusters = 2  # Number of clusters (cars and trucks)
agg_clustering = AgglomerativeClustering(n_clusters=num_clusters, affinity='precomputed', linkage='average')
cluster_labels = agg_clustering.fit_predict(distances)

# Print cluster labels
print("Cluster labels:", cluster_labels)

from sklearn.cluster import AgglomerativeClustering
from sklearn.metrics import pairwise_distances
from scipy.cluster.hierarchy import dendrogram, linkage


linkage_matrix = linkage(distances, method='manhattan')
plt.figure(figsize=(10, 5))
dendrogram(linkage_matrix, labels=cluster_labels, leaf_rotation=0, leaf_font_size=12)
plt.xlabel('Image Index')
plt.ylabel('Distance')
plt.title('Agglomerative Clustering Dendrogram')
plt.show()

"""Isolation Forest"""

from sklearn.ensemble import IsolationForest

clf = IsolationForest(contamination=0.1)  # Adjust contamination based on your dataset
clf.fit(all_images.reshape(len(all_images), -1))

# Predict anomaly scores
anomaly_scores = clf.score_samples(all_images.reshape(len(all_images), -1))

# Set anomaly threshold
anomaly_threshold = -0.5  # Adjust threshold based on your dataset and contamination

# Categorize images
categorized_images = ["Car" if score > anomaly_threshold else "Truck" for score in anomaly_scores]
print("Categorized images:", categorized_images)

plt.figure(figsize=(12, 6))
for i in range(5):
    plt.subplot(2, 5, i + 1)
    image = all_images[i]
    plt.imshow(image)
    plt.axis('off')

plt.show()

# Predict anomaly scores
anomaly_scores = clf.score_samples(all_images.reshape(len(all_images), -1))

# Plot histogram of anomaly scores
plt.hist(anomaly_scores, bins=50, density=True, alpha=0.7)
plt.xlabel('Anomaly Score')
plt.ylabel('Density')
plt.title('Anomaly Score Histogram')
plt.show()

"""tetst2"""

from sklearn.ensemble import IsolationForest

clf = IsolationForest(contamination=0.5)  # Adjust contamination based on your dataset
clf.fit(all_images.reshape(len(all_images), -1))

# Predict anomaly scores
anomaly_scores = clf.score_samples(all_images.reshape(len(all_images), -1))

# Set anomaly threshold
anomaly_threshold = -0.5  # Adjust threshold based on your dataset and contamination

# Categorize images
categorized_images = ["Car" if score > anomaly_threshold else "Truck" for score in anomaly_scores]
print("Categorized images:", categorized_images)

plt.figure(figsize=(12, 6))
for i in range(5):
    plt.subplot(2, 5, i + 1)
    image = all_images[i]
    plt.imshow(image)
    plt.axis('off')

plt.show()